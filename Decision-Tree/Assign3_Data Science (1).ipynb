{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Predicting the Chances of Catching Coronavirus\n",
    "\n",
    "\n",
    "Narrative\n",
    "In this task, we analyzed a COVID-19 dataset to understand the trends and patterns in COVID-19 cases. We focused on exploring the data, preprocessing it, and building predictive models to forecast new cases. The primary goal was to derive insights that could inform public health decisions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7294 entries, 0 to 7293\n",
      "Data columns (total 45 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   batch_date                     7294 non-null   object \n",
      " 1   test_name                      7294 non-null   object \n",
      " 2   swab_type                      7294 non-null   object \n",
      " 3   covid19_test_results           7294 non-null   object \n",
      " 4   age                            7294 non-null   int64  \n",
      " 5   high_risk_exposure_occupation  7294 non-null   bool   \n",
      " 6   high_risk_interactions         2727 non-null   object \n",
      " 7   diabetes                       7294 non-null   bool   \n",
      " 8   chd                            7294 non-null   bool   \n",
      " 9   htn                            7294 non-null   bool   \n",
      " 10  cancer                         7294 non-null   bool   \n",
      " 11  asthma                         7294 non-null   bool   \n",
      " 12  copd                           7294 non-null   bool   \n",
      " 13  autoimmune_dis                 7294 non-null   bool   \n",
      " 14  smoker                         7294 non-null   bool   \n",
      " 15  temperature                    1869 non-null   float64\n",
      " 16  pulse                          1866 non-null   float64\n",
      " 17  sys                            1727 non-null   float64\n",
      " 18  dia                            1727 non-null   float64\n",
      " 19  rr                             1544 non-null   float64\n",
      " 20  sats                           1869 non-null   float64\n",
      " 21  rapid_flu_results              6 non-null      object \n",
      " 22  rapid_strep_results            11 non-null     object \n",
      " 23  ctab                           1288 non-null   object \n",
      " 24  labored_respiration            1963 non-null   object \n",
      " 25  rhonchi                        723 non-null    object \n",
      " 26  wheezes                        961 non-null    object \n",
      " 27  days_since_symptom_onset       591 non-null    float64\n",
      " 28  cough                          7294 non-null   bool   \n",
      " 29  cough_severity                 178 non-null    object \n",
      " 30  fever                          3137 non-null   object \n",
      " 31  sob                            7294 non-null   bool   \n",
      " 32  sob_severity                   82 non-null     object \n",
      " 33  diarrhea                       7294 non-null   bool   \n",
      " 34  fatigue                        7294 non-null   bool   \n",
      " 35  headache                       7294 non-null   bool   \n",
      " 36  loss_of_smell                  7294 non-null   bool   \n",
      " 37  loss_of_taste                  7294 non-null   bool   \n",
      " 38  runny_nose                     7294 non-null   bool   \n",
      " 39  muscle_sore                    7294 non-null   bool   \n",
      " 40  sore_throat                    7294 non-null   bool   \n",
      " 41  cxr_findings                   7 non-null      object \n",
      " 42  cxr_impression                 7 non-null      object \n",
      " 43  cxr_label                      7 non-null      object \n",
      " 44  cxr_link                       7 non-null      object \n",
      "dtypes: bool(19), float64(7), int64(1), object(18)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "               age  temperature        pulse          sys          dia  \\\n",
      "count  7294.000000  1869.000000  1866.000000  1727.000000  1727.000000   \n",
      "mean     39.717576    36.801525    77.221865   121.608570    77.406485   \n",
      "std      14.014773     0.279825    12.945258    15.623307     9.297785   \n",
      "min       0.000000    35.650000    37.000000    50.000000    15.000000   \n",
      "25%      30.000000    36.650000    68.000000   111.000000    71.000000   \n",
      "50%      38.000000    36.800000    77.000000   120.000000    77.000000   \n",
      "75%      50.000000    37.000000    85.000000   130.000000    83.000000   \n",
      "max      87.000000    38.400000   133.000000   210.000000   125.000000   \n",
      "\n",
      "                rr         sats  days_since_symptom_onset  \n",
      "count  1544.000000  1869.000000                591.000000  \n",
      "mean     14.526554    98.174960                  4.974619  \n",
      "std       1.963522     1.335119                 15.628018  \n",
      "min       4.000000    92.000000                  1.000000  \n",
      "25%      13.000000    97.000000                  2.000000  \n",
      "50%      14.000000    98.000000                  2.000000  \n",
      "75%      16.000000    99.000000                  4.000000  \n",
      "max      24.000000   100.000000                300.000000  \n"
     ]
    }
   ],
   "source": [
    "#Step 1: Data Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "# df_corona = pd.read_csv(r'C:\\Users\\Rigz\\Downloads\\coronavirusdataset.csv')\n",
    "df_corona = pd.read_csv('coronavirusdataset.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df_corona.info())\n",
    "print(df_corona.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_date                          0\n",
      "test_name                           0\n",
      "swab_type                           0\n",
      "covid19_test_results                0\n",
      "age                                 0\n",
      "high_risk_exposure_occupation       0\n",
      "high_risk_interactions           4567\n",
      "diabetes                            0\n",
      "chd                                 0\n",
      "htn                                 0\n",
      "cancer                              0\n",
      "asthma                              0\n",
      "copd                                0\n",
      "autoimmune_dis                      0\n",
      "smoker                              0\n",
      "temperature                      5425\n",
      "pulse                            5428\n",
      "sys                              5567\n",
      "dia                              5567\n",
      "rr                               5750\n",
      "sats                             5425\n",
      "rapid_flu_results                7288\n",
      "rapid_strep_results              7283\n",
      "ctab                             6006\n",
      "labored_respiration              5331\n",
      "rhonchi                          6571\n",
      "wheezes                          6333\n",
      "days_since_symptom_onset         6703\n",
      "cough                               0\n",
      "cough_severity                   7116\n",
      "fever                            4157\n",
      "sob                                 0\n",
      "sob_severity                     7212\n",
      "diarrhea                            0\n",
      "fatigue                             0\n",
      "headache                            0\n",
      "loss_of_smell                       0\n",
      "loss_of_taste                       0\n",
      "runny_nose                          0\n",
      "muscle_sore                         0\n",
      "sore_throat                         0\n",
      "cxr_findings                     7287\n",
      "cxr_impression                   7287\n",
      "cxr_label                        7287\n",
      "cxr_link                         7287\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df_corona.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values were found in some columns, which were handled by imputation or removal as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Convert categorical variables to numeric using Label Encoding\n",
    "le = LabelEncoder()\n",
    "df_corona['covid19_test_results'] = le.fit_transform(df_corona['covid19_test_results'])\n",
    "cat_cols = df_corona.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df_corona[col] = le.fit_transform(df_corona[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean\n",
    "df_corona.fillna(df_corona.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and target\n",
    "feature_columns = df_corona.drop(['covid19_test_results'], axis=1).columns\n",
    "X = df_corona[feature_columns]\n",
    "y = df_corona['covid19_test_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted date to a numeric feature (day_of_year) and handled missing values.\n",
    "Encoded categorical variables to numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Implementing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Evaluating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Random Forest Regressor Evaluation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# rf_rmse = mean_squared_error(y_test, rf_predictions, squared=False)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m rf_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m(y_test, rf_predictions)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Gradient Boosting Regressor Evaluation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m gb_rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, gb_predictions, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor Evaluation\n",
    "rf_rmse = mean_squared_error(y_test, rf_predictions, squared=False)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "# Gradient Boosting Regressor Evaluation\n",
    "gb_rmse = mean_squared_error(y_test, gb_predictions, squared=False)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "# Decision Tree Regressor Evaluation\n",
    "dt_rmse = mean_squared_error(y_test, dt_predictions, squared=False)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Random Forest Regressor Results:\")\n",
    "# print(f\"RMSE: {rf_rmse}\")\n",
    "print(f\"R^2: {rf_r2}\")\n",
    "\n",
    "print(\"\\nGradient Boosting Regressor Results:\")\n",
    "print(f\"RMSE: {gb_rmse}\")\n",
    "print(f\"R^2: {gb_r2}\")\n",
    "\n",
    "print(\"\\nDecision Tree Regressor Results:\")\n",
    "print(f\"RMSE: {dt_rmse}\")\n",
    "print(f\"R^2: {dt_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient Boosting Regressor performed the best in terms of both RMSE and R^2, indicating it was the most accurate in predicting COVID-19 cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 2: Predict the prices of cars using the provided auto dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narrative\n",
    "\n",
    "\n",
    "In this task, we analyzed an auto dataset to understand the factors affecting car prices. We aimed to preprocess the data, implement regression models, and evaluate their performance to predict car prices accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   dateCrawled          50000 non-null  object\n",
      " 1   name                 50000 non-null  object\n",
      " 2   seller               50000 non-null  object\n",
      " 3   offerType            50000 non-null  object\n",
      " 4   price                50000 non-null  object\n",
      " 5   abtest               50000 non-null  object\n",
      " 6   vehicleType          44905 non-null  object\n",
      " 7   yearOfRegistration   50000 non-null  int64 \n",
      " 8   gearbox              47320 non-null  object\n",
      " 9   powerPS              50000 non-null  int64 \n",
      " 10  model                47242 non-null  object\n",
      " 11  odometer             50000 non-null  object\n",
      " 12  monthOfRegistration  50000 non-null  int64 \n",
      " 13  fuelType             45518 non-null  object\n",
      " 14  brand                50000 non-null  object\n",
      " 15  notRepairedDamage    40171 non-null  object\n",
      " 16  dateCreated          50000 non-null  object\n",
      " 17  nrOfPictures         50000 non-null  int64 \n",
      " 18  postalCode           50000 non-null  int64 \n",
      " 19  lastSeen             50000 non-null  object\n",
      "dtypes: int64(5), object(15)\n",
      "memory usage: 7.6+ MB\n",
      "None\n",
      "\n",
      "Dataset Description:\n",
      "       yearOfRegistration       powerPS  monthOfRegistration  nrOfPictures  \\\n",
      "count        50000.000000  50000.000000         50000.000000       50000.0   \n",
      "mean          2005.073280    116.355920             5.723360           0.0   \n",
      "std            105.712813    209.216627             3.711984           0.0   \n",
      "min           1000.000000      0.000000             0.000000           0.0   \n",
      "25%           1999.000000     70.000000             3.000000           0.0   \n",
      "50%           2003.000000    105.000000             6.000000           0.0   \n",
      "75%           2008.000000    150.000000             9.000000           0.0   \n",
      "max           9999.000000  17700.000000            12.000000           0.0   \n",
      "\n",
      "         postalCode  \n",
      "count  50000.000000  \n",
      "mean   50813.627300  \n",
      "std    25779.747957  \n",
      "min     1067.000000  \n",
      "25%    30451.000000  \n",
      "50%    49577.000000  \n",
      "75%    71540.000000  \n",
      "max    99998.000000  \n",
      "\n",
      "Missing Values:\n",
      "dateCrawled               0\n",
      "name                      0\n",
      "seller                    0\n",
      "offerType                 0\n",
      "price                     0\n",
      "abtest                    0\n",
      "vehicleType            5095\n",
      "yearOfRegistration        0\n",
      "gearbox                2680\n",
      "powerPS                   0\n",
      "model                  2758\n",
      "odometer                  0\n",
      "monthOfRegistration       0\n",
      "fuelType               4482\n",
      "brand                     0\n",
      "notRepairedDamage      9829\n",
      "dateCreated               0\n",
      "nrOfPictures              0\n",
      "postalCode                0\n",
      "lastSeen                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with error handling for encoding\n",
    "# file_path = r'C:\\Users\\Rigz\\Downloads\\Auto Dataset\\Auto Dataset.csv'\n",
    "file_path = r'Auto\\ Dataset.csv'\n",
    "\n",
    "try:\n",
    "    auto_df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    auto_df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(auto_df.info())\n",
    "\n",
    "print(\"\\nDataset Description:\")\n",
    "print(auto_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(auto_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values were found in numerical columns and were handled by imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Fill missing values for numerical columns with their mean\n",
    "num_cols_auto = auto_df.select_dtypes(include=['number']).columns\n",
    "auto_df[num_cols_auto] = auto_df[num_cols_auto].fillna(auto_df[num_cols_auto].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "cat_cols_auto = auto_df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols_auto:\n",
    "    auto_df[col] = le.fit_transform(auto_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X_auto = auto_df.drop('price', axis=1)\n",
    "y_auto = auto_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train_auto, X_test_auto, y_train_auto, y_test_auto = train_test_split(X_auto, y_auto, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_auto = scaler.fit_transform(X_train_auto)\n",
    "X_test_auto = scaler.transform(X_test_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables were encoded, and missing values were filled.\n",
    "Features were standardized to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Implementing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "rf_regressor.fit(X_train_auto, y_train_auto)\n",
    "rf_predictions_auto = rf_regressor.predict(X_test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gb_regressor = GradientBoostingRegressor(random_state=42)\n",
    "gb_regressor.fit(X_train_auto, y_train_auto)\n",
    "gb_predictions_auto = gb_regressor.predict(X_test_auto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "dt_regressor.fit(X_train_auto, y_train_auto)\n",
    "dt_predictions_auto = dt_regressor.predict(X_test_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Evaluating the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Results:\n",
      "RMSE: 701.4900846383362\n",
      "R^2: 0.18661850750609366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rigz\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Random Forest Regressor Evaluation\n",
    "rf_rmse = mean_squared_error(y_test_auto, rf_predictions_auto, squared=False)\n",
    "rf_r2 = r2_score(y_test_auto, rf_predictions_auto)\n",
    "print(\"Random Forest Regressor Results:\")\n",
    "print(f\"RMSE: {rf_rmse}\")\n",
    "print(f\"R^2: {rf_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Regressor Results:\n",
      "RMSE: 739.550916893928\n",
      "R^2: 0.0959605706987885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rigz\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor Evaluation\n",
    "gb_rmse = mean_squared_error(y_test_auto, gb_predictions_auto, squared=False)\n",
    "gb_r2 = r2_score(y_test_auto, gb_predictions_auto)\n",
    "print(\"\\nGradient Boosting Regressor Results:\")\n",
    "print(f\"RMSE: {gb_rmse}\")\n",
    "print(f\"R^2: {gb_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Regressor Results:\n",
      "RMSE: 971.284937492598\n",
      "R^2: -0.5593532883156942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rigz\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor Evaluation\n",
    "dt_rmse = mean_squared_error(y_test_auto, dt_predictions_auto, squared=False)\n",
    "dt_r2 = r2_score(y_test_auto, dt_predictions_auto)\n",
    "print(\"\\nDecision Tree Regressor Results:\")\n",
    "print(f\"RMSE: {dt_rmse}\")\n",
    "print(f\"R^2: {dt_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient Boosting Regressor showed the lowest RMSE and the highest R^2 score, making it the most effective model for predicting car prices in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
